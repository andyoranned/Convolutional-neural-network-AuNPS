{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6962511,"sourceType":"datasetVersion","datasetId":3970556},{"sourceId":7066343,"sourceType":"datasetVersion","datasetId":4068873},{"sourceId":7102171,"sourceType":"datasetVersion","datasetId":4094117}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 as cv #data processing\nfrom sklearn.model_selection import train_test_split #splits data into testing and training datasets\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import models, layers #used to make CNN model and provide layers\nfrom tensorflow.keras.optimizers import RMSprop #provides root mean squared propagation\nimport tensorflow.keras.losses\nimport tensorflow.keras.metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-02T02:23:18.717416Z","iopub.execute_input":"2023-12-02T02:23:18.717875Z","iopub.status.idle":"2023-12-02T02:23:18.784486Z","shell.execute_reply.started":"2023-12-02T02:23:18.717842Z","shell.execute_reply":"2023-12-02T02:23:18.783662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code heavily influenced by Arthur Arnx. His tutorial for preparing your own dataset, along with the original source code, can be found here: [Towards Data Science](https://towardsdatascience.com/all-the-steps-to-build-your-first-image-classifier-with-code-cf244b015799)\n\nNone of this would have beena ccomplished without the guidance of Dr. Tomitaka.\n\nThe architecture of the CNN is based on the LeNet-5 architecture. ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Prepare data:","metadata":{}},{"cell_type":"code","source":"\n\n#DATADIRs to switch between non-augmented data, goldnps & goldnps2(where poorest quality photos were removed), and data augmented with AI-generated data, midjaunps\n\n#DATADIR = \"/kaggle/input/goldnps2/\"\n#DATADIR = \"/kaggle/input/goldnps/\"\nDATADIR = \"/kaggle/input/midjaunps/\"\n\n# Categories which CNN will classify by\nCATEGORIES = [\"0\", \"10\", \"20\", \"30\", \"40\", \"50\", \"60\", \"70\", \"80\", \"90\", \"100\"]\n\n# The size of the images that your neural network will use\nIMG_SIZE = 100\n\n#Arrays to hold features and labels\nFEATURES = []\nAUGMENTED_FEATURES = []\nLABELS = []\nAUGMENTED_LABELS = []\n\n#FOR DATA AUGMENTATION Make an image data generator that will rotate, horizontally flip, tilt & zoom images\ngen = ImageDataGenerator(rotation_range = 10,\n                        width_shift_range = 0.1,\n                        height_shift_range = 0.1,\n                        shear_range =0.15,\n                        zoom_range = 0.1,\n                        horizontal_flip =True)\n\n\nfor c in CATEGORIES:  # access all folders\n    dataPath = os.path.join(DATADIR, c)  # create a path for each folder\n    classNum = CATEGORIES.index(c)\n    for img in os.listdir(dataPath):   # access all images in each folder\n        #preprocessing\n        #read image, in color\n        img = cv.imread(os.path.join(dataPath, img), cv.IMREAD_COLOR)\n        #Ensure every image is the same size\n        img = cv.resize(img,(IMG_SIZE, IMG_SIZE) )\n        #convert from BGR to YCrCb color space\n        img = cv.cvtColor(img, cv.COLOR_BGR2YCrCb)\n        \n        #RGB performed terrible compared to YCrCb\n        #img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        #normalize\n        img = img.astype(np.float32)/255\n        #add image & label to arrays\n        FEATURES.append(img)\n        LABELS.append(classNum)\n        \n        #Generate Augmented --- to break\n        #img = img.reshape((1,) + img.shape)\n         # Apply augmentation to generate additional images\n        #for batch in gen.flow(img, batch_size=1):\n        \n            # Incrementally append augmented images to the arrays\n            #aug_img = batch[0].astype(np.float32)\n            \n            #AUGMENTED_FEATURES.append(aug_img)\n            #AUGMENTED_LABELS.append(classNum)\n            \n            # Control the number of augmented images per original image\n            #if len(AUGMENTED_FEATURES) % 6 == 0:  # Change 6 to control augmentation factor\n                #break  # Stop after generating 6 augmented images per original image\n\n#FOR UNAUGMENTED DATA\nX = np.array(FEATURES)\ny = np.array(LABELS)\n\n#FOR AUGMENTED DATA                \n#put pictures into numpy array        \n#X_OG = np.array(FEATURES) #original image data\n#y_OG = np.array(LABELS)   #original labels\n#X_augmented = np.array(AUGMENTED_FEATURES)#augmented images\n#y_augmented = np.array(AUGMENTED_LABELS) #augmented images labels\n#X =np.concatenate((X_OG, X_augmented))\n#y =np.concatenate((y_OG, y_augmented))\n\n#split data into testing(20%) and training(80%) datasets\nFEATURES_train, FEATURES_test, LABELS_train, LABELS_test = train_test_split(X, y, train_size = .8)  \n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T02:23:18.786069Z","iopub.execute_input":"2023-12-02T02:23:18.786621Z","iopub.status.idle":"2023-12-02T02:23:20.370988Z","shell.execute_reply.started":"2023-12-02T02:23:18.786593Z","shell.execute_reply":"2023-12-02T02:23:20.369972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Augmentation","metadata":{}},{"cell_type":"code","source":"#Will be used to plot generated images\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes= axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axes('off')\n    plt.tight_layout()\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T02:23:20.372077Z","iopub.execute_input":"2023-12-02T02:23:20.372607Z","iopub.status.idle":"2023-12-02T02:23:20.378909Z","shell.execute_reply.started":"2023-12-02T02:23:20.372579Z","shell.execute_reply":"2023-12-02T02:23:20.377617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convolutional Neural Network Model based on early LeNet-5 architecture. ","metadata":{}},{"cell_type":"code","source":"#Model based on LeNet architecture\nmodel = models.Sequential([\n    layers.Conv2D(6, (5, 5), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n    layers.AveragePooling2D(pool_size= (2,2), strides= 2),\n    layers.Conv2D(16, (5, 5), activation='relu'),\n    layers.AveragePooling2D(pool_size= (2, 2), strides = 2),\n    layers.Flatten(),\n    layers.Dense(400, activation='relu'),\n    layers.Dense(180, activation='relu'),\n    layers.Dense(len(CATEGORIES), activation='softmax')\n])\n\n# set Root Mean Square Propogation's learning rate and decay factor\nrmsprop = RMSprop(learning_rate=0.001, rho=0.9)\n\n#Compile model and set optimize, loss function and metrics\nmodel.compile(optimizer= rmsprop,\n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\n#print a summary of the model\nmodel.summary()\n\nepochs = 15\n\n#train model\nhistory=model.fit(FEATURES_train, LABELS_train, epochs=epochs, validation_split=.1, batch_size=10, shuffle = True)\n\n#chart test accuracy/loss compared to validation accuracy/loss to catch things like overfitting\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()\n\n# evaluate the model with the test dataset\ntest_loss, test_acc= model.evaluate(FEATURES_test, LABELS_test)\nprint(f'Test accuracy: {test_acc * 100:.2f}%')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T02:24:02.838234Z","iopub.execute_input":"2023-12-02T02:24:02.838738Z","iopub.status.idle":"2023-12-02T02:24:16.992626Z","shell.execute_reply.started":"2023-12-02T02:24:02.838708Z","shell.execute_reply":"2023-12-02T02:24:16.991917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate model;","metadata":{}},{"cell_type":"code","source":"\n\n\n#Get true labels & predictions for classification report/confusion matrix\npred = model.predict(FEATURES_test, batch_size = 10)\npred = np.argmax(pred, axis = -1)\n\n#labels = np.argmax(LABELS_test, axis = -1)\nlabels = LABELS_test\n\n#Supposed to make a report showing three metrics F1,precision \nprint(\"Classification Report:\")\nprint(classification_report(labels, pred))\n\n# Generate confusion matrix\n#confusion_matrix = confusion_matrix(labels, pred)\n\n#print(\"Confusion Matrix:\")\n#print(conf_matrix)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T02:25:26.730481Z","iopub.execute_input":"2023-12-02T02:25:26.730838Z","iopub.status.idle":"2023-12-02T02:25:26.936499Z","shell.execute_reply.started":"2023-12-02T02:25:26.730811Z","shell.execute_reply":"2023-12-02T02:25:26.935479Z"},"trusted":true},"execution_count":null,"outputs":[]}]}